# Task ID: 3
# Title: Ollama Integration Module
# Status: pending
# Dependencies: 2 (Not found)
# Priority: high
# Description: Create the core module for integrating with Ollama LLM service
# Details:
Implement the OllamaClient class that handles connection to local Ollama service, model loading, and inference requests. Include error handling for connection failures, model not found, and timeout scenarios.

# Test Strategy:
Test connection to local Ollama instance, verify model loading, and test basic inference with sample prompts.
