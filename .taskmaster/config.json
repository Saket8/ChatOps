{
  "models": {
    "main": {
      "provider": "groq",
      "modelId": "llama-3.3-70b-versatile",
      "maxTokens": 32768,
      "temperature": 0.2
    },
    "research": {
      "provider": "groq",
      "modelId": "llama-4-maverick",
      "maxTokens": 32768,
      "temperature": 0.1
    },
    "fallback": {
      "provider": "groq",
      "modelId": "llama-3.1-8b-instant",
      "maxTokens": 131072,
      "temperature": 0.2
    }
  },
  "global": {
    "logLevel": "info",
    "debug": false,
    "defaultNumTasks": 10,
    "defaultSubtasks": 5,
    "defaultPriority": "medium",
    "projectName": "Taskmaster",
    "ollamaBaseURL": "http://localhost:11434/api",
    "bedrockBaseURL": "https://bedrock.us-east-1.amazonaws.com",
    "responseLanguage": "English",
    "defaultTag": "master",
    "azureOpenaiBaseURL": "https://your-endpoint.openai.azure.com/",
    "userId": "1234567890"
  },
  "claudeCode": {}
}